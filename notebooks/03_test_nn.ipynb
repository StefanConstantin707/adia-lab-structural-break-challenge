{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-24T19:14:30.553312Z",
     "start_time": "2025-06-24T19:14:28.417639Z"
    }
   },
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "from src.data.dataLoader import StructuralBreakDataLoader\n",
    "from src.data.sliding_window_dataset import create_dataset_for_training, create_dataset_for_testing\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch\n",
    "import torch.nn as nn"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T19:14:37.681047Z",
     "start_time": "2025-06-24T19:14:30.563820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_handler = StructuralBreakDataLoader()\n",
    "data_handler.load_data(use_crunch=False)\n",
    "train_dict, test_dict = data_handler.create_train_val_split(0.2)\n",
    "train_dataset, train_dataset_analysis = create_dataset_for_training(data_dict=train_dict, stride=1)\n",
    "test_dataset, test_dataset_analysis = create_dataset_for_testing(data_dict=test_dict)"
   ],
   "id": "c7c785b6627c52d3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.data.dataLoader:Data loaded successfully from local files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating sliding window dataset...\n",
      "Processed 100 series, generated 8100 windows so far...\n",
      "Processed 200 series, generated 16200 windows so far...\n",
      "Processed 300 series, generated 24300 windows so far...\n",
      "Processed 400 series, generated 32400 windows so far...\n",
      "Processed 500 series, generated 40500 windows so far...\n",
      "Processed 600 series, generated 48600 windows so far...\n",
      "Processed 700 series, generated 56700 windows so far...\n",
      "Processed 800 series, generated 64800 windows so far...\n",
      "Processed 900 series, generated 72900 windows so far...\n",
      "Processed 1000 series, generated 81000 windows so far...\n",
      "Processed 1100 series, generated 89100 windows so far...\n",
      "Processed 1200 series, generated 97200 windows so far...\n",
      "Processed 1300 series, generated 105300 windows so far...\n",
      "Processed 1400 series, generated 113400 windows so far...\n",
      "Processed 1500 series, generated 121500 windows so far...\n",
      "Processed 1600 series, generated 129600 windows so far...\n",
      "Processed 1700 series, generated 137700 windows so far...\n",
      "Processed 1800 series, generated 145800 windows so far...\n",
      "Processed 1900 series, generated 153900 windows so far...\n",
      "Processed 2000 series, generated 162000 windows so far...\n",
      "Processed 2100 series, generated 170100 windows so far...\n",
      "Processed 2200 series, generated 178200 windows so far...\n",
      "Processed 2300 series, generated 186300 windows so far...\n",
      "Processed 2400 series, generated 194400 windows so far...\n",
      "Processed 2500 series, generated 202500 windows so far...\n",
      "Processed 2600 series, generated 210600 windows so far...\n",
      "Processed 2700 series, generated 218700 windows so far...\n",
      "Processed 2800 series, generated 226800 windows so far...\n",
      "Processed 2900 series, generated 234900 windows so far...\n",
      "Processed 3000 series, generated 243000 windows so far...\n",
      "Processed 3100 series, generated 251100 windows so far...\n",
      "Processed 3200 series, generated 259200 windows so far...\n",
      "Processed 3300 series, generated 267300 windows so far...\n",
      "Processed 3400 series, generated 275400 windows so far...\n",
      "Processed 3500 series, generated 283500 windows so far...\n",
      "Processed 3600 series, generated 291600 windows so far...\n",
      "Processed 3700 series, generated 299700 windows so far...\n",
      "Processed 3800 series, generated 307800 windows so far...\n",
      "Processed 3900 series, generated 315900 windows so far...\n",
      "Processed 4000 series, generated 324000 windows so far...\n",
      "Processed 4100 series, generated 332100 windows so far...\n",
      "Processed 4200 series, generated 340200 windows so far...\n",
      "Processed 4300 series, generated 348300 windows so far...\n",
      "Processed 4400 series, generated 356400 windows so far...\n",
      "Processed 4500 series, generated 364500 windows so far...\n",
      "Processed 4600 series, generated 372600 windows so far...\n",
      "Processed 4700 series, generated 380700 windows so far...\n",
      "Processed 4800 series, generated 388800 windows so far...\n",
      "Processed 4900 series, generated 396900 windows so far...\n",
      "Processed 5000 series, generated 405000 windows so far...\n",
      "Processed 5100 series, generated 413100 windows so far...\n",
      "Processed 5200 series, generated 421200 windows so far...\n",
      "Processed 5300 series, generated 429300 windows so far...\n",
      "Processed 5400 series, generated 437400 windows so far...\n",
      "Processed 5500 series, generated 445500 windows so far...\n",
      "Processed 5600 series, generated 453600 windows so far...\n",
      "Processed 5700 series, generated 461700 windows so far...\n",
      "Processed 5800 series, generated 469800 windows so far...\n",
      "Processed 5900 series, generated 477900 windows so far...\n",
      "Processed 6000 series, generated 486000 windows so far...\n",
      "Processed 6100 series, generated 494100 windows so far...\n",
      "Processed 6200 series, generated 502200 windows so far...\n",
      "Processed 6300 series, generated 510300 windows so far...\n",
      "Processed 6400 series, generated 518400 windows so far...\n",
      "Processed 6500 series, generated 526500 windows so far...\n",
      "Processed 6600 series, generated 534600 windows so far...\n",
      "Processed 6700 series, generated 542700 windows so far...\n",
      "Processed 6800 series, generated 550800 windows so far...\n",
      "Processed 6900 series, generated 558900 windows so far...\n",
      "Processed 7000 series, generated 567000 windows so far...\n",
      "Processed 7100 series, generated 575100 windows so far...\n",
      "Processed 7200 series, generated 583200 windows so far...\n",
      "Processed 7300 series, generated 591300 windows so far...\n",
      "Processed 7400 series, generated 599400 windows so far...\n",
      "Processed 7500 series, generated 607500 windows so far...\n",
      "Processed 7600 series, generated 615600 windows so far...\n",
      "Processed 7700 series, generated 623700 windows so far...\n",
      "Processed 7800 series, generated 631800 windows so far...\n",
      "Processed 7900 series, generated 639900 windows so far...\n",
      "Processed 8000 series, generated 648000 windows so far...\n",
      "\n",
      "Dataset Statistics:\n",
      "Total windows: 648162\n",
      "Break windows: 188568\n",
      "No-break windows: 459594\n",
      "Break ratio: 0.291\n",
      "\n",
      "After balancing:\n",
      "Total windows: 628560\n",
      "Break windows: 188568\n",
      "No-break windows: 439992\n",
      "\n",
      "Dataset Analysis:\n",
      "Unique series: 8002\n",
      "Avg windows per series: 78.6\n",
      "Class balance: 0.300\n",
      "Created dataset with 628560 samples\n",
      "Creating sliding window dataset...\n",
      "Processed 100 series, generated 100 windows so far...\n",
      "Processed 200 series, generated 200 windows so far...\n",
      "Processed 300 series, generated 300 windows so far...\n",
      "Processed 400 series, generated 400 windows so far...\n",
      "Processed 500 series, generated 500 windows so far...\n",
      "Processed 600 series, generated 600 windows so far...\n",
      "Processed 700 series, generated 700 windows so far...\n",
      "Processed 800 series, generated 800 windows so far...\n",
      "Processed 900 series, generated 900 windows so far...\n",
      "Processed 1000 series, generated 1000 windows so far...\n",
      "Processed 1100 series, generated 1100 windows so far...\n",
      "Processed 1200 series, generated 1200 windows so far...\n",
      "Processed 1300 series, generated 1300 windows so far...\n",
      "Processed 1400 series, generated 1400 windows so far...\n",
      "Processed 1500 series, generated 1500 windows so far...\n",
      "Processed 1600 series, generated 1600 windows so far...\n",
      "Processed 1700 series, generated 1700 windows so far...\n",
      "Processed 1800 series, generated 1800 windows so far...\n",
      "Processed 1900 series, generated 1900 windows so far...\n",
      "\n",
      "Dataset Statistics:\n",
      "Total windows: 1999\n",
      "Break windows: 581\n",
      "No-break windows: 1418\n",
      "Break ratio: 0.291\n",
      "\n",
      "Dataset Analysis:\n",
      "Unique series: 1999\n",
      "Avg windows per series: 1.0\n",
      "Class balance: 0.291\n",
      "Created dataset with 1999 samples\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T19:15:29.075378Z",
     "start_time": "2025-06-24T19:15:29.072080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainDataLoader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "testDataLoader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)"
   ],
   "id": "4c7387414c8fba73",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T19:15:30.295944Z",
     "start_time": "2025-06-24T19:15:30.287960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, output_size, num_layers, noise=0.0, dropout_prob=0.0):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        - input_size: Number of input features.\n",
    "        - hidden_dim: Dimension of the hidden layers.\n",
    "        - output_size: Number of output features.\n",
    "        - use_noise: Whether to apply Gaussian noise to the input.\n",
    "        - dropout_prob: Dropout probability. Set to 0.0 to disable dropout.\n",
    "        - num_hidden_layers: Number of fully connected hidden layers.\n",
    "        \"\"\"\n",
    "        super(SimpleNN, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.dropout_prob = dropout_prob\n",
    "\n",
    "        # Define layers dynamically using nn.Sequential\n",
    "        layers = []\n",
    "\n",
    "        # layers.append(GaussianNoise(std=noise))\n",
    "\n",
    "        # Input layer\n",
    "        layers.append(nn.Linear(self.input_size, hidden_dim))\n",
    "        layers.append(nn.ReLU())\n",
    "\n",
    "        # Add additional hidden layers\n",
    "        for _ in range(num_layers - 1):\n",
    "            layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_prob))\n",
    "\n",
    "        # Output layer\n",
    "        layers.append(nn.Linear(hidden_dim, output_size))\n",
    "\n",
    "        # Combine into a Sequential module\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass the input through the sequential layers\n",
    "        out = self.network(x)\n",
    "        return out\n"
   ],
   "id": "d77c4c8d88dd54b5",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T19:30:42.424544700Z",
     "start_time": "2025-06-24T19:15:32.514691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model   = SimpleNN(input_size=200, hidden_dim=64, output_size=1,\n",
    "                   num_layers=2, noise=0.0, dropout_prob=0.0)\n",
    "loss_fct = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "for epoch in range(10):\n",
    "    # ---- TRAINING ----\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch in trainDataLoader:\n",
    "        X = batch[\"window\"]            # [batch, 100]\n",
    "        y = batch[\"has_break\"].float() # [batch] or [batch,1]\n",
    "\n",
    "        optimizer.zero_grad()          # reset grads\n",
    "        logits = model(X)              # forward\n",
    "        loss   = loss_fct(logits.squeeze(), y.squeeze())\n",
    "        loss.backward()                # backward\n",
    "        optimizer.step()               # update params\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_loss / len(trainDataLoader)\n",
    "    \n",
    "    # ---- EVALUATION ----\n",
    "    model.eval()\n",
    "    y_trues, y_scores = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in testDataLoader:\n",
    "            X = batch[\"window\"]\n",
    "            y = batch[\"has_break\"].float()\n",
    "            logits = model(X)\n",
    "\n",
    "            # collect\n",
    "            y_trues.append(y.view(-1).cpu())\n",
    "            y_scores.append(logits.view(-1).cpu())\n",
    "    \n",
    "    # concatenate everything\n",
    "    y_true  = torch.cat(y_trues).numpy()\n",
    "    y_score = torch.cat(y_scores).numpy()\n",
    "    roc_auc = roc_auc_score(y_true, y_score)\n",
    "\n",
    "    print(f\"Epoch {epoch+1:2d} — Train loss: {avg_train_loss:.4f}    ROC-AUC: {roc_auc:.4f}\")\n"
   ],
   "id": "5992a3d10b6b01a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 — Train loss: 0.6115    ROC-AUC: 0.5000\n",
      "Epoch  2 — Train loss: 0.6118    ROC-AUC: 0.5000\n",
      "Epoch  3 — Train loss: 0.6108    ROC-AUC: 0.5000\n",
      "Epoch  4 — Train loss: 0.6109    ROC-AUC: 0.5000\n",
      "Epoch  5 — Train loss: 0.6108    ROC-AUC: 0.5000\n",
      "Epoch  6 — Train loss: 0.6113    ROC-AUC: 0.5000\n",
      "Epoch  7 — Train loss: 0.6110    ROC-AUC: 0.5000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[13]\u001B[39m\u001B[32m, line 15\u001B[39m\n\u001B[32m     12\u001B[39m y = batch[\u001B[33m\"\u001B[39m\u001B[33mhas_break\u001B[39m\u001B[33m\"\u001B[39m].float() \u001B[38;5;66;03m# [batch] or [batch,1]\u001B[39;00m\n\u001B[32m     14\u001B[39m optimizer.zero_grad()          \u001B[38;5;66;03m# reset grads\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m15\u001B[39m logits = \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m              \u001B[38;5;66;03m# forward\u001B[39;00m\n\u001B[32m     16\u001B[39m loss   = loss_fct(logits.squeeze(), y.squeeze())\n\u001B[32m     17\u001B[39m loss.backward()                \u001B[38;5;66;03m# backward\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\Git\\Python\\ADIA Lab Structural Break Challenge\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\Git\\Python\\ADIA Lab Structural Break Challenge\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[12]\u001B[39m\u001B[32m, line 43\u001B[39m, in \u001B[36mSimpleNN.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m     41\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[32m     42\u001B[39m     \u001B[38;5;66;03m# Pass the input through the sequential layers\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m43\u001B[39m     out = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mnetwork\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     44\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\Git\\Python\\ADIA Lab Structural Break Challenge\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\Git\\Python\\ADIA Lab Structural Break Challenge\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\Git\\Python\\ADIA Lab Structural Break Challenge\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:240\u001B[39m, in \u001B[36mSequential.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    238\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[32m    239\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m240\u001B[39m         \u001B[38;5;28minput\u001B[39m = \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    241\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\Git\\Python\\ADIA Lab Structural Break Challenge\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\Git\\Python\\ADIA Lab Structural Break Challenge\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\Git\\Python\\ADIA Lab Structural Break Challenge\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001B[39m, in \u001B[36mLinear.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    124\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) -> Tensor:\n\u001B[32m--> \u001B[39m\u001B[32m125\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T18:59:05.686008600Z",
     "start_time": "2025-06-24T13:51:43.020404Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "8523618c9076c465",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Union' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 31\u001B[39m\n\u001B[32m     27\u001B[39m         decoded = \u001B[38;5;28mself\u001B[39m.decoder(encoded)\n\u001B[32m     28\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m decoded, encoded\n\u001B[32m     30\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mextract_autoencoder_features\u001B[39m(\n\u001B[32m---> \u001B[39m\u001B[32m31\u001B[39m     data: \u001B[43mUnion\u001B[49m[pd.DataFrame, TimeSeriesData],\n\u001B[32m     32\u001B[39m     max_length: \u001B[38;5;28mint\u001B[39m = \u001B[32m200\u001B[39m,\n\u001B[32m     33\u001B[39m     encoding_dim: \u001B[38;5;28mint\u001B[39m = \u001B[32m16\u001B[39m\n\u001B[32m     34\u001B[39m ) -> Dict[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mfloat\u001B[39m]:\n\u001B[32m     35\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Extract autoencoder-based features\"\"\"\u001B[39;00m\n\u001B[32m     36\u001B[39m     features = {}\n",
      "\u001B[31mNameError\u001B[39m: name 'Union' is not defined"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
